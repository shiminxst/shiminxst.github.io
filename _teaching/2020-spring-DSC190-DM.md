---
title: "2020-Spring-DSC190-Introduction to Data Mining"
collection: teaching
type: "Undergraduate Class"
permalink: /teaching/2020-spring-DSC190-DM
venue: "HDSI, UCSD"
date: 2020-03-25
location: "La Jolla, CA"
---

**Class Time**: Tuesdays and Thursdays, 9:30AM to 10:50AM.  **Room**: [https://ucsd.zoom.us/j/632116245](https://ucsd.zoom.us/j/632116245).  **Piazza**: [piazza.com/ucsd/spring2020/dsc190a00](https://piazza.com/ucsd/spring2020/dsc190a00)


Online Lecturing
======

Due to the COVID-19, this course will be delivered over Zoom: [https://ucsd.zoom.us/j/632116245](https://ucsd.zoom.us/j/632116245)

Overview
======

This course mainly focuses on introducing current methods and models that are useful in analyzing and mining real-world data. It will cover frequent pattern mining, regression & classification, clustering, and representation learning. No previous background in machine learning is required, but all participants should be comfortable with programming, and with basic optimization and linear algebra. 

There is no textbook required, but here are some recommended readings:
- The classical data mining textbook "[Data Mining: Concepts and Techniques](https://books.google.com/books/about/Data_Mining_Concepts_and_Techniques.html?id=pQws07tdpjoC&source=kp_book_description)" by Jiawei Han et al.
- The classical data mining/machine learning book "[Pattern Recognition and Machine Learning](https://books.google.com/books/about/Pattern_Recognition_and_Machine_Learning.html?id=HL4HrgEACAAJ&source=kp_book_description)" by Christopher M. Bishop
- The new "[Dive into Deep Learning](https://d2l.ai/)" book by Aston Zhang et al.


Prerequisites
======

Math, Stats, and Coding: `(CSE 12 or DSC 40B) and (CSE 15L or DSC 80) and (CSE 103 or ECE 109 or MATH 181A or ECON 120A or MATH 183)`

TAs and Tutors
======

- **Teaching Assistants**: Ria Aggarwal (r2aggarw AT eng.ucsd.edu) and Dheeraj Mekala (dmekala AT eng.ucsd.edu)
- **Tutors**: Zhenyu Bi (z1bi AT ucsd.edu) and Yang Li (yang AT ucsd.edu)

Office Hours
======

- Monday 8 - 9:30 AM: Ria Aggarwal [https://ucsd.zoom.us/j/7575561942](https://ucsd.zoom.us/j/7575561942)
- Monday 4 - 5 PM: Zhenyu Bi [https://ucsd.zoom.us/j/6198663088](https://ucsd.zoom.us/j/6198663088)
- Tuesday 11 AM - 12:30 PM: Dheeraj Mekala [https://ucsd.zoom.us/j/513621310](https://ucsd.zoom.us/j/513621310)
- Wednesday 4 - 6 PM: Yang Li [https://ucsd.zoom.us/j/7558015559](https://ucsd.zoom.us/j/7558015559)
- Wednesday 12 - 1:30 PM: Ria Aggarwal [https://ucsd.zoom.us/j/7575561942](https://ucsd.zoom.us/j/7575561942)
- Thursday 11 AM - 12:30 PM: Dheeraj Mekala [https://ucsd.zoom.us/j/513621310](https://ucsd.zoom.us/j/513621310)
- Friday 8 - 9 AM: Zhenyu Bi [https://ucsd.zoom.us/j/6198663088](https://ucsd.zoom.us/j/6198663088)
- Friday 9 AM - 12:30 PM: Jingbo Shang [https://ucsd.zoom.us/my/jshang](https://ucsd.zoom.us/my/jshang)

Note: all times are in **Pacific Time**.

Grading
======

- Homework: 8% each. Your lowest (of four) homework grades is dropped (or one homework can be skipped).
- Midterm: 26%.
- Data Mining Challenge: 25%.
- Project: 25%.
- You should complete all work individually, except for the Project.
- Late submissions are NOT accepted.

Lecture Schedule
======

**Recording Note**: Please download the recording video for the full length. Dropbox website will only show you the first one hour.

**HW Note**: All HWs due before the lecture time 9:30 AM PT in the morning. 

Week | Date        | Topic & Slides                                                  | Events
1    | 03/31 (Tue) | Introduction: Data Types, Tasks, and Evaluations [[slides](https://www.dropbox.com/s/8ktrdg4po8t7wjm/lecture0_intro.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/8sf4vfl881vjrbr/AACegM1GSKg7QVSOEjKWby5Ja?dl=0)] | HW1 out
1    | 04/02 (Thu) | Supervised - Least-Squares Regression and Logistic Regression [[slides](https://www.dropbox.com/s/aokgf4oxsf353d7/lecture1_least_square_and_logistic.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/ncqhd1tkcu6sh2a/AAAE-fIOzigqgRJngkOKm8vma?dl=0)]   |
2    | 04/07 (Tue) | Supervised - Overfitting and Regularization [[slides](https://www.dropbox.com/s/utx11qqs3p5fxgv/lecture2_overfitting.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/hlk4hvkwsdnyv1d/%5Bannotated%5Dlecture2_overfitting.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/l43nkim25n2yamk/AAD3dBCwfYYVm3jakmGUijx8a?dl=0)]                    | HW1 Due, HW2 out
2    | 04/09 (Thu) | Supervised - Support Vector Machine [[slides](https://www.dropbox.com/s/m2jsrmyxxx3alr0/lecture3_svm.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/spacnme2i2dncyc/%5Bannotated%5Dlecture3_svm.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/xuuybzcrr3bop66/AADSM2luNTwLnP27tIgVuPhRa?dl=0)] |
3    | 04/14 (Tue) | Supervised - Naive Bayes and Decision Tree [[slides](https://www.dropbox.com/s/xpd8yc1s9nccjpx/lecture4_nb_and_dt.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/give0uiop3sibiq/%5Bannotated%5Dlecture4_nb_and_dt.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/hv5ce2dtiutewxh/AADn5br5Oz5vAMKaFCuTsbrHa?dl=0)] |
3    | 04/16 (Thu) | Supervised - Ensemble Learning: Bagging and Boosting [[slides](https://www.dropbox.com/s/devszefh407l6s7/lecture5_ensemble.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/r4mrovlxn5mzs2k/%5Bannotated%5D_lecture5_ensemble.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/6pqdnfmn0t822sk/AABpHxtLcfp4Ufo8GY9Dj123a?dl=0)] | 
4    | 04/21 (Tue) | Cluster Analysis - K-Means Clustering & its Variants [[slides](https://www.dropbox.com/s/xfcrq46af1uoial/lecture6_kmeans.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/ho42sful2wmcnp8/%5Bannotated%5Dlecture6_kmeans.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/ssmz8lmo7hq0gur/AABDGopCweY9unZIepNtjs7oa?dl=0)]          | HW2 Due, HW3 out
4    | 04/23 (Thu) | Cluster Analysis - "Soft" Clustering: Gaussian Mixture [[slides](https://www.dropbox.com/s/507g6wh7lkkl2wd/lecture7_gaussin_mixture.pdf?dl=0)] [[annotated_slides](https://www.dropbox.com/s/zi27bise8ruo1ew/%5Bannotated%5Dlecture7_gaussin_mixture.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/m52w7x6ufb8799k/AAANJGVEynBD3GzBIrzTxKE4a?dl=0)]        |
5    | 04/28 (Tue) | Cluster Analysis - Density-based Clustering: DBSCAN [[slides](https://www.dropbox.com/s/3lrwhhrrxzo5fcw/lecture8_dbscan.pdf?dl=0)] [[annotated_slides](https://www.dropbox.com/s/cf88u8wdqwztl6s/%5Bannotated%5Dlecture8_dbscan.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/ylcq9op1w3tr4yv/AAA_5ryhCpDO6n8Q7vs4uFg3a?dl=0)] |
5    | 04/30 (Thu) | Cluster Analysis - Principle Component Analysis [[slides](https://www.dropbox.com/s/aku5gzor8bqvh99/lecture9_pca.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/lb5ddj78rjtfjjr/%5Bannotated%5Dlecture9_pca.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/urc6jjoru4utymw/AAABZWct4zLt9kegz3jeXUHda?dl=0)] | DM Challenge out
6    | 05/05 (Tue) | Pattern Analysis - Frequent Pattern and Association Rules [[slides](https://www.dropbox.com/s/n512q1vel7lr9iy/lecture10_pattern_analysis.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/szojaar5o567j6n/%5Bannotated%5Dlecture10_pattern_analysis.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/ke0afqx1j7v9rpt/AAAOccdU9j92oOv69iojtUtFa?dl=0)]      |
6    | 05/07 (Thu) | Midterm (24 hours on this date) |
7    | 05/12 (Tue) | Recommender System - Collaborative Filtering [[slides](https://www.dropbox.com/s/i3nkezli4cgwqfb/lecture11_cf.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/dju1sljknfhc3kp/%5Bannotated%5Dlecture11_cf.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/oo6cu2otxwetull/AAAQv_lJlWJPrD0SU7fankyHa?dl=0)]                    | HW3 Due, HW4 out
7    | 05/14 (Thu) | Recommender System - Latent Factor Models [[slides](https://www.dropbox.com/s/go6btf7c38m3o6d/lecture12_mf.pdf?dl=0)] [[annoated slides](https://www.dropbox.com/s/s1zb3a3i8xvagwi/%5Bannotated%5Dlecture12_mf.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/sy1b0ec2ywdv1ig/AACNfoisRsGesPpvcK2RNiZOa?dl=0)]                   |
8    | 05/19 (Tue) | Text Mining - Zipf's Law, Bags-of-words, and TF-IDF [[slides](https://www.dropbox.com/s/k4orebohuriynnl/lecture13_text_basics.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/h2fulgdp7x36aja/%5Bannotated%5Dlecture13_text_basics.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/rcqrid6lkc3wov2/AACbjBdX2SR5SurFRsvsRkY9a?dl=0)]           |
8    | 05/21 (Thu) | Text Mining - Advanced Text Representations [[slides](https://www.dropbox.com/s/vqpkriyhsg9zidn/lecture14_text_advanced.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/qys7fnxbjuhv12h/%5Bannotated%5Dlecture14_text_advanced.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/c8l984eyhc4n52r/AACtnhwyR_0DjMcxeBJJyh96a?dl=0)] |
9    | 05/26 (Tue) | Network Mining - Small-Worlds & Random Graph Models [[slides](https://www.dropbox.com/s/h7w1ty2ep4q1y0w/lecture15_DM_challenge_and_graph_basics.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/hbms2na0hiqlnfi/%5Bannotated%5Dlecture15_DM_challenge_and_graph_basics.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/y3hoga3gfo00vxd/AAAkw-ox_v7QOHd35SymDYCta?dl=0)]           | 
9    | 05/28 (Thu) | Network Mining - HITS, PageRank, Personalized PageRank and Node Embedding [[slides](https://www.dropbox.com/s/73gea8stj6llcr4/lecture16_graph_advanced.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/06ikllomykd3mp5/%5Bannotated%5Dlecture16_graph_advanced.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/z42676lmftmoyhm/AABobgWzncsVWDdghWD4u_4Xa?dl=0)] |
10   | 06/02 (Tue) | Sequence Mining - Sliding Windows and Autoregression [[slides](https://www.dropbox.com/s/mnwufnoqha4mwbz/lecture17_time_series.pdf?dl=0)] [[annotated slides](https://www.dropbox.com/s/sy9q3i4l84vm6ug/%5Bannotated%5Dlecture17_time_series.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/dh7h2mlb7em4cx7/AADIzRXradZmHFXGWfsbVuHfa?dl=0)] |
10   | 06/04 (Thu) | Text Data as Sequence - Named Entitry Recognition [[slides](https://www.dropbox.com/s/jp579krqhh4enb2/lecture18_ner.pdf?dl=0)] [[annotated slide](https://www.dropbox.com/s/rem05g8c7ap22g8/%5Bannotated%5Dlecture18_ner.pdf?dl=0)] [[recording](https://www.dropbox.com/sh/u0jfa7wnwyggzvv/AAAMkBmhA1IOZHq5s-SWGS1ua?dl=0)] | HW4 Due **extended to 06/07 9:30 AM PT**

Homework (24%)
======

Your lowest (of four) homework grades is dropped (or one homework can be skipped). Gradescope code: `M665VN`. 

- **[HW1: Concepts and Evaluations (8%)](https://www.dropbox.com/s/mh82m8j5kig46sk/DSC190-Spring20-HW1.pdf?dl=1).** This homework mainly focuses on the data mining concepts and how to evaluate different tasks.
- **[HW2: Regression and Classification (8%)](https://www.dropbox.com/s/zfnnf4r9bb1ue7v/HW2.zip?dl=1).** This homework mainly focuses on regression and classification tasks.
- **[HW3: Cluster and Pattern Analysis (8%)](https://www.dropbox.com/s/y5ed4qvh5g1862r/HW3.zip?dl=1).** This homework mainly focuses on clustering methods and frequent pattern mining methods.
- **[HW4: Applications (8%)](https://www.dropbox.com/s/43snxcsime3qm3o/HW4.zip?dl=1).** This homework mainly focuses on recommender system, text mining, and network mining.

Midterm (26%)
======

It is an open-book, take-home exam, which covers all lectures given before the Midterm. Most of the questions will be open-ended. Some of them might be slightly more difficult than homework. You will have 24 hours to complete the midterm, which is expected for about 2 hours.

- **Start**: May 7, 9:30 AM PT
- **End**: May 8, 9:30 AM PT
- [Midterm problems download](https://www.dropbox.com/s/3qrozs1g0qe37xq/DSC190-Spring20-Midterm%20Exam.pdf?dl=1).
- Please **make your submissions on Gradescope**.

Data Mining Challenge (25%)
======

It is a individual-based data mining competition with quantitative evaluation. The challenge runs **from April 30 0:00:01 AM to May 17 4:59:59 PM PT**. Note that the time displayed on Kaggle is in UTC, not PT.

- Challenge Statement, Dataset, and Details: [here](https://www.dropbox.com/s/hogx3ovlnx2o0vf/DSC%20190_%20Intro%20to%20Data%20Mining%20%E2%80%93%20Data%20Mining%20Challenge.pdf?dl=0).
- Kaggle challenge link: [https://www.kaggle.com/t/f7cbcf2b349e461ca7650289f109caed](https://www.kaggle.com/t/f7cbcf2b349e461ca7650289f109caed)

Project (25%)
======

Instructions for both choices are available [here](https://www.dropbox.com/s/15gociykle5sigl/Project%20Instructions.pdf?dl=0). Project **due extended to Jun 9**.

Here is a quick overview:
- **Choice 1: Team-Based Open-Ended Project**
    - 1 to 4 members per team. More members, higher expectation.
    - Define your own research problem and justify its importance
    - Come up with your hypothesis and find some datasets for verification
    - Design your own models or try a large variety of existing models
    - Write a 4 to 8 pages report (research-paper like)
    - Submit your codes
    - Up to 5% bonus for working demos/apps towards the total course grade.
- **Choice 2: Individual-Based Deep Dive into Data Mining Methods**
    - Implement a few models learned from this course from scratch.
    - Skeleton codes will be provided. Your work is more like "filling in blanks".
    - Each model has a point associated with it. 6 points required.
    - Write a report (pages based on points) describing your interesting findings.
    - Up to 5% bonus towards the total course grade. Roughly 1 point, 1%.
