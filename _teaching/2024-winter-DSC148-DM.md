---
title: "2024-Winter-DSC148-Introduction to Data Mining"
collection: teaching
type: "Undergraduate Class"
permalink: /teaching/2024-winter-DSC148-DM
venue: "HDSI, UCSD"
date: 2024-01-09
location: "La Jolla, CA"
---

**Class Time**: Tuesdays and Thursdays, 11AM to 12:20PM.  **Room**: CENTR 212 (1st week over Zoom).  **Piazza**: [piazza.com/ucsd/winter2024/dsc148](https://piazza.com/ucsd/winter2024/dsc148)

Online Lecturing
======


To offer waitlist students opportunities to learn more about this course, in the first week, we deliver the lectures over Zoom: [https://ucsd.zoom.us/j/97017584161](https://ucsd.zoom.us/j/97017584161). These lectures will be recorded. 



Overview
======

This course mainly focuses on introducing current methods and models that are useful in analyzing and mining real-world data. It will cover frequent pattern mining, regression & classification, clustering, and representation learning. No previous background in machine learning is required, but all participants should be comfortable with programming, and with basic optimization and linear algebra. 

There is no textbook required, but here are some recommended readings:
- The classical data mining textbook "[Data Mining: Concepts and Techniques](https://books.google.com/books/about/Data_Mining_Concepts_and_Techniques.html?id=pQws07tdpjoC&source=kp_book_description)" by Jiawei Han et al.
- The classical data mining/machine learning book "[Pattern Recognition and Machine Learning](https://books.google.com/books/about/Pattern_Recognition_and_Machine_Learning.html?id=HL4HrgEACAAJ&source=kp_book_description)" by Christopher M. Bishop
- The new "[Dive into Deep Learning](https://d2l.ai/)" book by Aston Zhang et al.


Prerequisites
======

Math, Stats, and Coding: `(CSE 12 or DSC 40B) and (CSE 15L or DSC 80) and (CSE 103 or ECE 109 or MATH 181A or ECON 120A or MATH 183)`

TAs
======

- **Teaching Assistants**: Bill Hogan (whogan AT ucsd.edu), Weitang Liu (wel022 AT ucsd.edu), and Yufan Zhuang (y5zhuang AT ucsd.edu)

Office Hours
======

- Jingbo Shang
    - Office Hour: Wednesdays, 10 to 11 AM
    - Zoom link: [https://ucsd.zoom.us/my/jshang](https://ucsd.zoom.us/my/jshang)
- Bill Hogan
    - Office Hour: Mondays, 10 to 11 AM
    - Zoom link: [https://ucsd.zoom.us/my/billh](https://ucsd.zoom.us/my/billh)
- Weitang Liu
    - Office Hour: Fridays, 7pm to 8pm
    - Zoom link: [https://ucsd.zoom.us/j/93170362758](https://ucsd.zoom.us/j/93170362758)
- Yufan Zhuang
    - Office Hour: Wednesdays, 11am to 12pm
    - Zoom link: [https://ucsd.zoom.us/j/7971151616](https://ucsd.zoom.us/j/7971151616)

Note: all times are in **Pacific Time**.

Grading
======

- Homework: 8% each. Your lowest (of four) homework grades is dropped (or one homework can be skipped).
- Midterm: 26%.
- Data Mining Challenge: 25%.
- Project: 25%.
- You should complete all work individually, except for the Project.
- Late submissions are NOT accepted.

Lecture Schedule
======

**Recording Note**: Please download the recording video for the full length. Dropbox website will only show you the first one hour.

**HW Note**: All HWs due by the end of the day on the due date, i.e., 11:59 PM PT. 

Week | Date        | Topic & Slides                                                  | Events
1    | 01/09 (Tue) | [Introduction: Data Types, Tasks, and Evaluations](https://www.dropbox.com/scl/fo/o2jyr2zh42qj74lcjxlso/h?rlkey=l4zwc7azavxjqb9e3ooxvsbix&dl=0) | [HW1 out](https://www.dropbox.com/scl/fi/22lf6ti11tp7djspxdp37/DSC148_HW1.pdf?rlkey=yzemrk2gzsabrduhkdl596x27&dl=0)
1    | 01/11 (Thu) | [Supervised - Least-Squares Regression and Logistic Regression](https://www.dropbox.com/scl/fo/k48vpzsb9astxjs4szslw/h?rlkey=nzvk6jcizpmmccirjnw1w3j7x&dl=0) |
2    | 01/16 (Tue) | [Supervised - Overfitting and Regularization](https://www.dropbox.com/scl/fo/rg0806eogkamcfz6irwrx/h?rlkey=gz1ritb718myr98p0zdijf7zt&dl=0) | [HW2 out](https://www.dropbox.com/scl/fi/dco7zyni1dtus47ge5d51/DSC148_W24_HW2.pdf?rlkey=ppbyjfovx2cnmkh8b5a48au2s&dl=0)
2    | 01/18 (Thu) | [Supervised - Support Vector Machine](https://www.dropbox.com/scl/fo/e35238s8dh9f187qi3qd5/h?rlkey=crdmjjzuxpuw00a1gslxrhgas&dl=0) | HW1 Due
3    | 01/23 (Tue) | [Supervised - Naive Bayes and Decision Tree](https://www.dropbox.com/scl/fo/4xste1vsp4ungmq0x8ogk/h?rlkey=bto53rtadqcuy9x6dfxk832z7&dl=0) |
3    | 01/25 (Thu) | [Supervised - Ensemble Learning: Bagging and Boosting](https://www.dropbox.com/scl/fo/t0k0plzfg8e3s3lnc57za/h?rlkey=qqip0nq52fwgclmhu5be8ou55&dl=0) | 
4    | 01/30 (Tue) | [Cluster Analysis - K-Means Clustering & its Variants](https://www.dropbox.com/scl/fo/68mar2dwtfy8bjlt57udi/h?rlkey=o1564idx4z3ahscnayb84mj6a&dl=0) | HW2 Due, [HW3 out](https://www.dropbox.com/scl/fi/l313itllwpdg79h54qqe8/DSC148_W24_HW3.pdf?rlkey=qs8z7m9azicy4yrcgcqawvida&dl=0)
4    | 02/01 (Thu) | [Cluster Analysis - "Soft" Clustering: Gaussian Mixture](https://www.dropbox.com/scl/fo/9g3e3zcph732ygn5qg10v/h?rlkey=8oxhlu5qb4xzfev4l0yrhsocz&dl=0) |
5    | 02/06 (Tue) | [Cluster Analysis - Density-based Clustering: DBSCAN](https://www.dropbox.com/scl/fo/x61vmvhd9rl28geaxmvmn/h?rlkey=4fwmvsio76qldwdmp50f077pj&dl=0) |
5    | 02/08 (Thu) | [Cluster Analysis - Principle Component Analysis](https://www.dropbox.com/scl/fo/thywjvhjb1pxizx3lufq6/h?rlkey=97goddx5ljhvbgy491clwqyb6&dl=0) | [DM Challenge out](https://www.dropbox.com/scl/fi/vgaqnqw61infuaqigkscn/DSC-148_-Intro-to-Data-Mining-Data-Mining-Challenge.pdf?rlkey=d2cx62vyk6j6zu4s4ncgoqzez&dl=0)
6    | 02/13 (Tue) | [Pattern Analysis - Frequent Pattern and Association Rules](https://www.dropbox.com/scl/fo/kveodn83xatcayyvtjff7/h?rlkey=d9npxxnh4ixkxe43r1pgj7kwx&dl=0)  |
6    | 02/15 (Thu) | Midterm (no class, 24 hours on this date) |
7    | 02/20 (Tue) | [Recommender System - Collaborative Filtering](https://www.dropbox.com/scl/fo/rh2g0xjdex83ygtzoyi5e/h?rlkey=rz3gojbu0yrlwoal9699i7dit&dl=0) | HW3 Due, [HW4 out](https://www.dropbox.com/scl/fi/abirx9tzcyugnsmz23wzi/DSC148_W24_HW4.pdf?rlkey=jyxbtsd5q1utwtd1pptkgblb5&dl=0)
7    | 02/22 (Thu) | [Recommender System - Latent Factor Models](https://www.dropbox.com/scl/fo/8mzsj04kbesjy0wk4mqg0/h?rlkey=r9f1czfg4rvs3nl3f07nj1mge&dl=0) |
8    | 02/27 (Tue) | [Text Mining - Zipf's Law, Bags-of-words, and TF-IDF](https://www.dropbox.com/scl/fo/53ezazaawzzhnx0mhgoxb/h?rlkey=dyoojnrt4lic3ou9l96w96pzo&dl=0) |
8    | 02/29 (Thu) | [Text Mining - Advanced Text Representations](https://www.dropbox.com/scl/fo/xbwjoe0jqqe7w982l6iid/h?rlkey=qd8oiek4moxagtxg5afq0hyky&dl=0) | DM Challenge due
9    | 03/05 (Tue) | [Network Mining - Small-Worlds & Random Graph Models, HITS, PageRank](https://www.dropbox.com/scl/fo/291nslrn6qfkizbbo4h8a/h?rlkey=h4ticzjwe1jv88ty1l8aaxnyh&dl=0) | 
9    | 03/07 (Thu) | [Network Mining - Personalized PageRank and Node Embedding](https://www.dropbox.com/scl/fo/azc11oyolbl3yqilm2dvr/h?rlkey=qthvd2l9c2166rc4jaksflw2u&dl=0) |
10   | 03/12 (Tue) | [Sequence Mining - Sliding Windows and Autoregression](https://www.dropbox.com/scl/fo/uhwbpyrdwbu47pvkq7xpa/h?rlkey=ngp8333sawsjbf96f6ed6lxc8&dl=0) |
10   | 03/14 (Thu) | [Text Data as Sequence - Named Entity Recognition](https://www.dropbox.com/scl/fo/o072idrmuto10zun0qula/h?rlkey=nhj4iw5ckdvc6ga091pmf7o39&dl=0) | HW4 Due

Homework (24%)
======

Your lowest (of four) homework grades is dropped (or one homework can be skipped).

- **[HW1: Concepts and Evaluations](https://www.dropbox.com/scl/fi/22lf6ti11tp7djspxdp37/DSC148_HW1.pdf?rlkey=yzemrk2gzsabrduhkdl596x27&dl=0) (8%).** This homework mainly focuses on the data mining concepts and how to evaluate different tasks.
- **[HW2: Regression and Classification](https://www.dropbox.com/scl/fi/dco7zyni1dtus47ge5d51/DSC148_W24_HW2.pdf?rlkey=ppbyjfovx2cnmkh8b5a48au2s&dl=0) (8%).** This homework mainly focuses on regression and classification tasks.
- **[HW3: Cluster and Pattern Analysis](https://www.dropbox.com/scl/fi/l313itllwpdg79h54qqe8/DSC148_W24_HW3.pdf?rlkey=qs8z7m9azicy4yrcgcqawvida&dl=0) (8%).** This homework mainly focuses on clustering methods and frequent pattern mining methods.
- **[HW4: Applications](https://www.dropbox.com/scl/fi/abirx9tzcyugnsmz23wzi/DSC148_W24_HW4.pdf?rlkey=jyxbtsd5q1utwtd1pptkgblb5&dl=0) (8%).** This homework mainly focuses on recommender system, text mining, and network mining.

Midterm (26%)
======

It is an open-book, take-home exam, which covers all lectures given before the Midterm. Most of the questions will be open-ended. Some of them might be slightly more difficult than homework. You will have 24 hours to complete the midterm, which is expected for about 3 to 4 hours.

- **Start**: Feb 15, 11 AM PT
- **End**: Feb 16, 11 AM PT
- Midterm problems download: TBD
- Please **make your submissions on Gradescope**.

Data Mining Challenge (25%)
======

It is a individual-based data mining competition with quantitative evaluation. The challenge runs **from Feb 8 to Feb 29**. Note that the time displayed on Kaggle is in UTC, not PT.

- [Challenge Statement, Dataset, and Details](https://www.dropbox.com/scl/fi/vgaqnqw61infuaqigkscn/DSC-148_-Intro-to-Data-Mining-Data-Mining-Challenge.pdf?rlkey=d2cx62vyk6j6zu4s4ncgoqzez&dl=0)
- [Kaggle challenge link](https://www.kaggle.com/competitions/ucsd-dsc148-w24-introduction-to-data-mining)

Project (25%)
======

Instructions for both choices will be available [here](https://www.dropbox.com/s/aqkk6q6hjtpzwbq/Project%20Instructions.pdf?dl=0). Project **due on Sunday, Mar 17 End of the Day**.

Here is a quick overview:
- **Choice 1: Team-Based Open-Ended Project**
    - 1 to 4 members per team. More members, higher expectation.
    - Define your own research problem and justify its importance
    - Come up with your hypothesis and find some datasets for verification
    - Design your own models or try a large variety of existing models
    - Write a 4 to 8 pages report (research-paper like)
    - Submit your codes
    - Up to 5% bonus for working demos/apps towards the total course grade.
- **Choice 2: Individual-Based Deep Dive into Data Mining Methods**
    - Implement a few models learned from this course from scratch.
    - Skeleton codes can be found [here](https://www.dropbox.com/sh/y5a5wvrysbl7mrd/AAARcWGHjlWRN9E-6B9H3KFCa?dl=0). Your work is more like "filling in blanks" following the TODOs outlined in the Jupyter-Notebook.
    - Each model has a point associated with it. 6 points required. Points for each model is available at the end of the instruction slides.
    - Write a report (pages based on points) describing your interesting findings.
    - Up to 5% bonus towards the total course grade. Roughly 1 point, 1%.

Sample project reports are [here](https://www.dropbox.com/sh/6h2x141rh6if95g/AABnk8dVw3SbbHIYadXsn7Hba?dl=0).